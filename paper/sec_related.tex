% vim:syntax=tex

In this section we provide an overview of latent Dirichlet allocation and review closely related work.

%    The indexing process is illustrated on the left side of Figure~\ref{fig:process}.
%    It converts source code into a corpus, or collection of documents.
%    A document is a collection of terms that appear in a source code entity.
%    Each entity in the source code will have an associated document in the resulting corpus.
%
%    Typically, this indexing process has been used on source code files ~\cite{Marcus-etal:2004}.
%    Hindle et al.~\cite{Hindle-etal:2009} creates tokens based on the commit log messages.
%    This model is similar to ours in that it uses tokens mined from commits rather than source code files.
%    Nevertheless, we are unaware of any previous approach to indexing that is similar to what we propose,
%    and our investigation of using indexing with LDA is the first of its kind in the software engineering domain.

%    Model generation is depicted in the center of Figure~\ref{fig:process}.
%    This stage takes a corpus as input and processes it using a TR method
%    to produce a model of the source code as output.
%    The TR methods commonly used in this stage include the VSM~\cite{Salton:1971},
%    LSI~\cite{Deerwester-etal:1990},
%    and LDA~\cite{Blei-etal:2003}.

\subsection{Latent Dirichlet Allocation}

Latent Dirichlet allocation (LDA)~\cite{Blei-etal:2003} is a generative topic model.
LDA models each document in a corpus of discrete data as a finite mixture over a set of topics
and models each topic as an infinite mixture over a set of topic probabilities.
That is, LDA models each document as a probability distribution
indicating the likelihood that it expresses each topic and
models each topic that it infers as a probability distribution
indicating the likelihood of a word from the corpus being assigned to the topic.

%Inputs to LDA include a corpus and $K$, the number of topics. LDA represents each document in the corpus as a bag-of-word (multiset) and thus disregards word order and structure. Outputs of LDA include $\phi$, the term-topic probability distribution, and $\theta$, the topic-document probability distribution.


\subsection{Topic Models in Software Maintenance}

%Feature location as presented by Rajlich et al.\ is a way of locating concepts within code to increase understanding of the program as a whole~\cite{Rajlich-Wilde:2002}.
%Linstead et al.\ outlined a statistical model using LDA that was able to mine these concepts from source code~\cite{Linstead-etal:2007b}.
%Linstead et al.~\cite{Linstead-etal:2007} used author-topic models to retrieve
%developer contribtions from source code.
%Lukins et al.~\cite{Lukins-etal:2008} implemented a way of using LDA to locate bugs in source
%code that performed better than LSI-based information-retrieval
%techniques.
%Basset et al.~\cite{Bassett-Kraft:2013} extended this work
%and studied various weightings of various terms in source code
%to improve LDA-based feature location accuracy in five Java systems.

Thomas et al.~\cite{Thomas-etal:2011} describe an approach to modeling the evolution of source code topics using LDA. Their \textit{Diff} model outperforms the Hall topic evolution model~\cite{Hall_etal:2008} in the context of software repositories, because the \textit{Diff} model trains topic models on the changesets rather than on snapshots. That is, for a particular source code file, \textit{Diff} trains a topic model on documents that represent the changes between consecutive versions of the file. Consequently, the \textit{Diff} model eliminates the issues related to data duplication that arise in the Hall model, which trains a topic model on all versions of the (whole) file. Thomas et al.\ demonstrate the efficacy of the \textit{Diff} model via a comparative study with the Hall model. Their evaluation measures include topic distinctness, which we define in Section~\ref{sec:study}.

Hindle et al.~\cite{Hindle_etal:2012} validate the use LDA topics during software maintenance via a study at Microsoft. Their focus is on stakeholder validation of topics --- i.e., they seek confirmation that LDA topics are interpretable by stakeholders (e.g., developers or managers) and relevant to the requirements implemented by the modeled source code. Previous work by Hindle et al.~\cite{Hindle-etal:2009} describes an approach to modeling the evolution of software topics using commit messages rather than source code.

Although our work is preliminary, we believe that it is the first to consider modeling changesets in lieu of snapshots to support software maintenance. Like Rao et al.~\cite{Rao-etal:2011}, we are targeting problems that require an up-to-date topic model. Thus, the expense of training a topic model is a key consideration for us, unlike for Thomas et al.~\cite{Thomas-etal:2011} or Hindle et al.~\cite{Hindle-etal:2009,Hindle_etal:2012}.

\begin{comment}
Software source code is often compiled through a series of commits that change the source code between releases.
These commits can be of many sizes from a small change in a function to additions of many functions.
The person who commits these changes is seen as being the owner of the code~\cite{Corley-etal:2012}.
The owner of the code is assumed to have a greater working knowledge of the code in question than other members of the design team.
Being able to determine who would know most about a certain topic would allow someone working on a design team to know who is best fit to solve an issue pertaining to a certain topic.
Unfortunately, most of the topic modeling that is currently used to determine ownership is only based off of larger releases rather than intermediate changes.
These types of topic models can be problematic if you are working between releases.
Think for a second that you are a project manager at a software company with a rapidly approaching release deadline.
There is a problem of some sort with the code, and through the use of a topic model you could be able to identify precisely who should be delegated the task of fixing it.
With the type of dynamic topic model like we are proposing, this is easily attainable.
A model based on the change sets between commits would allow software developers never to have an obsolete model.
While there has been some research in the use of commit log comments~\cite{Hindle-etal:2009}, we are not aware of any analyses of topic models that have been created by using the differences of the source code between commits.
\end{comment}
